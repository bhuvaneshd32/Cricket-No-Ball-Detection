{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UNzOR7gXqz-u"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import DirectoryIterator, ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "maB3-fDJx0hk"
   },
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYpZL9O5q6JT",
    "outputId": "5183d390-d3f6-48e9-ae64-9b8aae92cb10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2225 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = DirectoryIterator(directory = 'Large-image-dataset/training',\n",
    "                                 image_data_generator = ImageDataGenerator(rescale=1.0/255),\n",
    "                                 target_size = (64, 64),\n",
    "                                 batch_size = 32,\n",
    "                                 shuffle = False,  \n",
    "                                 class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SEFaFqYqsND3",
    "outputId": "e3342adf-3628-4073-96f6-fa27d87b5423"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n",
      "{'Legal': 762, 'No ball': 1463}\n"
     ]
    }
   ],
   "source": [
    "print(training_set.classes)\n",
    "unique, counts = np.unique(training_set.classes, return_counts=True)\n",
    "print(dict(zip(training_set.class_indices, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dB_RNEDJ8Bv5",
    "outputId": "a2423c5e-3337-4628-c650-6af17196ccd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2225\n"
     ]
    }
   ],
   "source": [
    "print(training_set.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Xg0t4URs1dO",
    "outputId": "67889900-f355-447a-99c8-2c92c69922a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "\n",
    "# Initialize empty lists for training data\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "# Iterate through the training set and collect the data\n",
    "i=1\n",
    "for x, y in training_set:\n",
    "    print(i)\n",
    "    i+=1\n",
    "    X_train.extend(x)\n",
    "    y_train.extend(y)\n",
    "    if len(X_train) >= training_set.samples:\n",
    "        break\n",
    "# Convert the lists into numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# Reshape the image data to a 2D array (flatten each image)\n",
    "X_train_reshaped = X_train.reshape(X_train.shape[0], -1)\n",
    "\n",
    "# Apply SMOTE to the reshaped training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train_reshaped, y_train)\n",
    "\n",
    "# Reshape the resampled data back to its original 4D shape (64x64 images with 3 color channels)\n",
    "X_resampled = X_resampled.reshape(-1, 64, 64, 3)\n",
    "\n",
    "# Shuffle the resampled data\n",
    "X_resampled, y_resampled = shuffle(X_resampled, y_resampled, random_state=42)\n",
    "\n",
    "# Now you have X_resampled and y_resampled with balanced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2926, 64, 64, 3)\n",
      "(2926,)\n"
     ]
    }
   ],
   "source": [
    "print(X_resampled.shape)\n",
    "print(y_resampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "AIXJnV7pxKjo"
   },
   "outputs": [],
   "source": [
    "new_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create the new training set using the resampled data\n",
    "training_set_resampled = new_datagen.flow(X_resampled, y_resampled, batch_size=32)\n",
    "# Convert X_resampled and y_resampled into a TensorFlow dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_resampled, y_resampled))\n",
    "\n",
    "# Shuffle, batch, and optionally prefetch the data for efficient training\n",
    "training_set_smote = train_dataset.shuffle(buffer_size=1024).batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# Use this dataset in your model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nqWbkt0q8mFx",
    "outputId": "d728215c-d305-4c54-d1bc-175af7ebaf8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "{0.0: 1463, 1.0: 1463}\n"
     ]
    }
   ],
   "source": [
    "print(y_resampled)\n",
    "unique, counts = np.unique(y_resampled, return_counts=True)\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QkHcGrAy_Ojp",
    "outputId": "cde4095e-6f01-421a-89f0-020608a5852c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 262 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_set = DirectoryIterator(directory = 'Large-image-dataset/validation',\n",
    "                                   image_data_generator = ImageDataGenerator(rescale = 1.0/255),\n",
    "                                   target_size = (64, 64),\n",
    "                                   batch_size = 32,\n",
    "                                   shuffle = False,\n",
    "                                   class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "S3O7OJlFs0uE"
   },
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', input_shape=(64, 64, 3)))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "eyIaweMbvNWK"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 64)        1792      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 61504)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               7872640   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,874,561\n",
      "Trainable params: 7,874,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Zgdcb2myvW1t"
   },
   "outputs": [],
   "source": [
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6yetyas-vaLZ",
    "outputId": "4410e22b-1e33-4709-da0e-691c709373c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "92/92 [==============================] - 11s 98ms/step - loss: 0.7331 - accuracy: 0.7068 - val_loss: 0.3740 - val_accuracy: 0.8435\n",
      "Epoch 2/10\n",
      "92/92 [==============================] - 8s 90ms/step - loss: 0.2496 - accuracy: 0.9019 - val_loss: 0.2819 - val_accuracy: 0.9122\n",
      "Epoch 3/10\n",
      "92/92 [==============================] - 8s 92ms/step - loss: 0.1321 - accuracy: 0.9576 - val_loss: 0.1901 - val_accuracy: 0.9695\n",
      "Epoch 4/10\n",
      "92/92 [==============================] - 8s 82ms/step - loss: 0.0616 - accuracy: 0.9856 - val_loss: 0.1899 - val_accuracy: 0.9656\n",
      "Epoch 5/10\n",
      "92/92 [==============================] - 8s 85ms/step - loss: 0.0584 - accuracy: 0.9846 - val_loss: 0.1938 - val_accuracy: 0.9695\n",
      "Epoch 6/10\n",
      "92/92 [==============================] - 8s 89ms/step - loss: 0.0312 - accuracy: 0.9952 - val_loss: 0.1975 - val_accuracy: 0.9771\n",
      "Epoch 7/10\n",
      "92/92 [==============================] - 10s 107ms/step - loss: 0.0104 - accuracy: 0.9997 - val_loss: 0.2111 - val_accuracy: 0.9771\n",
      "Epoch 8/10\n",
      "92/92 [==============================] - 9s 102ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.2238 - val_accuracy: 0.9771\n",
      "Epoch 9/10\n",
      "92/92 [==============================] - 8s 88ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2505 - val_accuracy: 0.9733\n",
      "Epoch 10/10\n",
      "92/92 [==============================] - 8s 88ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2389 - val_accuracy: 0.9771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x250ed2bd3c0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x = training_set_smote, validation_data = validation_set, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Rybu9rMaGfpg"
   },
   "outputs": [],
   "source": [
    "cnn.save('final_cnn.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zf1-MNqyxoHv"
   },
   "source": [
    "### Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "loaded_model = tf.keras.models.load_model(r'final_cnn.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 16s 229ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Training Loss: 0.0024889539927244186\n",
      "Training Accuracy: 1.0\n",
      "70/70 [==============================] - 16s 228ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       762\n",
      "           1       1.00      1.00      1.00      1463\n",
      "\n",
      "    accuracy                           1.00      2225\n",
      "   macro avg       1.00      1.00      1.00      2225\n",
      "weighted avg       1.00      1.00      1.00      2225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = loaded_model.evaluate(training_set)\n",
    "\n",
    "print(\"Training Loss:\", loss)\n",
    "print(\"Training Accuracy:\", accuracy)\n",
    "\n",
    "y_pred = loaded_model.predict(training_set)\n",
    "y_pred = [1 if i[0] >= 0.5 else 0 for i in y_pred]\n",
    "\n",
    "print(classification_report(training_set.classes.tolist(), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 2s 236ms/step - loss: 0.2389 - accuracy: 0.9771\n",
      "Validation Loss: 0.2389112412929535\n",
      "Validation Accuracy: 0.9770992398262024\n",
      "9/9 [==============================] - 2s 226ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       129\n",
      "           1       0.96      0.99      0.98       133\n",
      "\n",
      "    accuracy                           0.98       262\n",
      "   macro avg       0.98      0.98      0.98       262\n",
      "weighted avg       0.98      0.98      0.98       262\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = loaded_model.evaluate(validation_set)\n",
    "\n",
    "print(\"Validation Loss:\", loss)\n",
    "print(\"Validation Accuracy:\", accuracy)\n",
    "\n",
    "y_pred = loaded_model.predict(validation_set)\n",
    "y_pred = [1 if i[0] >= 0.5 else 0 for i in y_pred]\n",
    "\n",
    "print(classification_report(validation_set.classes.tolist(), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 262 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "testing_set = DirectoryIterator(directory = 'Large-image-dataset/testing',\n",
    "                                image_data_generator = ImageDataGenerator(rescale = 1.0/255),\n",
    "                                target_size = (64, 64),\n",
    "                                batch_size = 32,\n",
    "                                shuffle = False,\n",
    "                                class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "05ZWeXMq_xAl",
    "outputId": "b8cf331f-abee-4131-d926-0460bb786f95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 2s 225ms/step - loss: 0.2389 - accuracy: 0.9771\n",
      "Testing Loss: 0.2389112412929535\n",
      "Testing Accuracy: 0.9770992398262024\n",
      "9/9 [==============================] - 2s 198ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       129\n",
      "           1       0.96      0.99      0.98       133\n",
      "\n",
      "    accuracy                           0.98       262\n",
      "   macro avg       0.98      0.98      0.98       262\n",
      "weighted avg       0.98      0.98      0.98       262\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = loaded_model.evaluate(testing_set)\n",
    "\n",
    "print(\"Testing Loss:\", loss)\n",
    "print(\"Testing Accuracy:\", accuracy)\n",
    "\n",
    "y_pred = loaded_model.predict(testing_set)\n",
    "y_pred = [1 if i[0] >= 0.5 else 0 for i in y_pred]\n",
    "\n",
    "print(classification_report(testing_set.classes.tolist(), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(testing_set.classes.tolist())\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h7QKsPFnvOML",
    "outputId": "64bbc3b8-dd76-462c-ac74-19d941c7f868"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 92ms/step\n",
      "[[0.]]\n",
      "Legal Ball\n"
     ]
    }
   ],
   "source": [
    "# Load the test image\n",
    "image_location = r'test\\legal.jpg'\n",
    "\n",
    "test_image = image.load_img(image_location, target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "\n",
    "# Now you can use the loaded_model for predictions or further training\n",
    "result = loaded_model.predict(test_image)\n",
    "print(result)\n",
    "\n",
    "if result[0][0] < 0.5:\n",
    "  prediction = 'Legal Ball'\n",
    "else:\n",
    "  prediction = 'No Ball'\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5EyUMR0IwBgI",
    "outputId": "50d169de-e967-41d2-b1eb-37e797801e37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "[[0.]]\n",
      "Legal Ball\n"
     ]
    }
   ],
   "source": [
    "# Load the test image\n",
    "image_location = r'test\\noball_1.jpg'\n",
    "\n",
    "test_image = image.load_img(image_location, target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "\n",
    "# Now you can use the loaded_model for predictions or further training\n",
    "result = loaded_model.predict(test_image)\n",
    "print(result)\n",
    "\n",
    "if result[0][0] < 0.5:\n",
    "  prediction = 'Legal Ball'\n",
    "else:\n",
    "  prediction = 'No Ball'\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "[[1.]]\n",
      "No Ball\n"
     ]
    }
   ],
   "source": [
    "# Load the test image\n",
    "image_location = r'test\\noball_2.jpg'\n",
    "\n",
    "test_image = image.load_img(image_location, target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "\n",
    "# Now you can use the loaded_model for predictions or further training\n",
    "result = loaded_model.predict(test_image)\n",
    "print(result)\n",
    "\n",
    "if result[0][0] < 0.5:\n",
    "  prediction = 'Legal Ball'\n",
    "else:\n",
    "  prediction = 'No Ball'\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 77 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "testing_set = DirectoryIterator(directory = 'Small-image-dataset',\n",
    "                                image_data_generator = ImageDataGenerator(rescale = 1.0/255),\n",
    "                                target_size = (64, 64),\n",
    "                                batch_size = 32,\n",
    "                                shuffle = False,\n",
    "                                class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 73ms/step - loss: 1.8324 - accuracy: 0.7143\n",
      "Testing Loss: 1.8324109315872192\n",
      "Testing Accuracy: 0.7142857313156128\n",
      "3/3 [==============================] - 0s 83ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.60      0.58        25\n",
      "           1       0.80      0.77      0.78        52\n",
      "\n",
      "    accuracy                           0.71        77\n",
      "   macro avg       0.68      0.68      0.68        77\n",
      "weighted avg       0.72      0.71      0.72        77\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = loaded_model.evaluate(testing_set)\n",
    "\n",
    "print(\"Testing Loss:\", loss)\n",
    "print(\"Testing Accuracy:\", accuracy)\n",
    "\n",
    "y_pred = loaded_model.predict(testing_set)\n",
    "y_pred = [1 if i[0] >= 0.5 else 0 for i in y_pred]\n",
    "\n",
    "print(classification_report(testing_set.classes.tolist(), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "testing_set = DirectoryIterator(directory = 'Final-test',\n",
    "                                image_data_generator = ImageDataGenerator(rescale = 1.0/255),\n",
    "                                target_size = (64, 64),\n",
    "                                batch_size = 32,\n",
    "                                shuffle = False,\n",
    "                                class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Testing Loss: 0.004129423759877682\n",
      "Testing Accuracy: 1.0\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00        10\n",
      "   macro avg       1.00      1.00      1.00        10\n",
      "weighted avg       1.00      1.00      1.00        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = loaded_model.evaluate(testing_set)\n",
    "\n",
    "print(\"Testing Loss:\", loss)\n",
    "print(\"Testing Accuracy:\", accuracy)\n",
    "\n",
    "y_pred = loaded_model.predict(testing_set)\n",
    "y_pred = [1 if i[0] >= 0.5 else 0 for i in y_pred]\n",
    "\n",
    "print(classification_report(testing_set.classes.tolist(), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FT7t3eJ_HtLT",
    "outputId": "3bf3b79e-2353-4a99-ac9b-b752b884f9e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.version.VERSION)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
