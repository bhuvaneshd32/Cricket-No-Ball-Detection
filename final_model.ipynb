{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNzOR7gXqz-u"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model training"
      ],
      "metadata": {
        "id": "maB3-fDJx0hk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/Data/Large-image-dataset/training',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYpZL9O5q6JT",
        "outputId": "4d8b3a86-0a2c-408c-bc82-025376e179f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2246 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(training_set.classes)\n",
        "unique, counts = np.unique(training_set.classes, return_counts=True)\n",
        "print(dict(zip(training_set.class_indices, counts)))"
      ],
      "metadata": {
        "id": "SEFaFqYqsND3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a830614-69d4-4ab4-86c4-b97c01be7b04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 ... 1 1 1]\n",
            "{'Legal': 773, 'No ball': 1473}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(training_set.samples)"
      ],
      "metadata": {
        "id": "dB_RNEDJ8Bv5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "653b004d-acc3-45a5-c764-6038fa503297"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.utils import shuffle\n",
        "import numpy as np\n",
        "\n",
        "# Initialize empty lists for training data\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "# Iterate through the training set and collect the data\n",
        "i=1\n",
        "for x, y in training_set:\n",
        "    print(i)\n",
        "    i+=1\n",
        "    X_train.extend(x)\n",
        "    y_train.extend(y)\n",
        "    if len(X_train) >= training_set.samples:\n",
        "        break\n",
        "# Convert the lists into numpy arrays\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "# Reshape the image data to a 2D array (flatten each image)\n",
        "X_train_reshaped = X_train.reshape(X_train.shape[0], -1)\n",
        "\n",
        "# Apply SMOTE to the reshaped training data\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_train_reshaped, y_train)\n",
        "\n",
        "# Reshape the resampled data back to its original 4D shape (64x64 images with 3 color channels)\n",
        "X_resampled = X_resampled.reshape(-1, 64, 64, 3)\n",
        "\n",
        "# Shuffle the resampled data\n",
        "X_resampled, y_resampled = shuffle(X_resampled, y_resampled, random_state=42)\n",
        "\n",
        "# Now you have X_resampled and y_resampled with balanced classes\n"
      ],
      "metadata": {
        "id": "6Xg0t4URs1dO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49a13376-f8fa-4126-a6b8-2a2c29504842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_resampled.shape)\n",
        "print(y_resampled.shape)"
      ],
      "metadata": {
        "id": "eZBerPqo8eXc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baa4bed8-ce9a-4002-d816-4fbc46011a84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2946, 64, 64, 3)\n",
            "(2946,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Create the new training set using the resampled data\n",
        "training_set_resampled = new_datagen.flow(X_resampled, y_resampled, batch_size=32)\n",
        "# Convert X_resampled and y_resampled into a TensorFlow dataset\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_resampled, y_resampled))\n",
        "\n",
        "# Shuffle, batch, and optionally prefetch the data for efficient training\n",
        "training_set = train_dataset.shuffle(buffer_size=1024).batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "# Use this dataset in your model training"
      ],
      "metadata": {
        "id": "AIXJnV7pxKjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_resampled)\n",
        "unique, counts = np.unique(y_resampled, return_counts=True)\n",
        "print(dict(zip(unique, counts)))"
      ],
      "metadata": {
        "id": "nqWbkt0q8mFx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79cb389e-0340-4860-d9a0-6007e4a28672"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. ... 0. 1. 1.]\n",
            "{0.0: 1473, 1.0: 1473}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/Data/Large-image-dataset/testing',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'binary')"
      ],
      "metadata": {
        "id": "bYy6eM66rK6z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f3d5a44-e2ca-433a-b3ea-5320d9101f2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 262 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "S3O7OJlFs0uE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
      ],
      "metadata": {
        "id": "napVRX21sAcs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d288ba53-032d-4c75-9156-d6ba4d8ed098"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "metadata": {
        "id": "punKs1d2vGui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "metadata": {
        "id": "Vt0ziLJBvJ0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "metadata": {
        "id": "eyIaweMbvNWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
      ],
      "metadata": {
        "id": "VvQWw76ZvP4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "IN5WZFJRvUJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "Zgdcb2myvW1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.fit(x = training_set, validation_data = test_set, epochs = 10)"
      ],
      "metadata": {
        "id": "6yetyas-vaLZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fcca826-9619-40e1-ce61-259b4f37dcf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m92/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.6045 - loss: 0.6798"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 703ms/step - accuracy: 0.6058 - loss: 0.6782 - val_accuracy: 0.7595 - val_loss: 0.5055\n",
            "Epoch 2/10\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 178ms/step - accuracy: 0.7613 - loss: 0.4665 - val_accuracy: 0.8588 - val_loss: 0.3794\n",
            "Epoch 3/10\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 174ms/step - accuracy: 0.9022 - loss: 0.2521 - val_accuracy: 0.8702 - val_loss: 0.3592\n",
            "Epoch 4/10\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 174ms/step - accuracy: 0.9372 - loss: 0.1609 - val_accuracy: 0.8931 - val_loss: 0.2835\n",
            "Epoch 5/10\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 173ms/step - accuracy: 0.9566 - loss: 0.1159 - val_accuracy: 0.8702 - val_loss: 0.4482\n",
            "Epoch 6/10\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 167ms/step - accuracy: 0.9689 - loss: 0.0867 - val_accuracy: 0.8740 - val_loss: 0.4841\n",
            "Epoch 7/10\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 166ms/step - accuracy: 0.9595 - loss: 0.0991 - val_accuracy: 0.9160 - val_loss: 0.3705\n",
            "Epoch 8/10\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 174ms/step - accuracy: 0.9847 - loss: 0.0429 - val_accuracy: 0.9046 - val_loss: 0.4482\n",
            "Epoch 9/10\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 177ms/step - accuracy: 0.9895 - loss: 0.0321 - val_accuracy: 0.8359 - val_loss: 0.6440\n",
            "Epoch 10/10\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 173ms/step - accuracy: 0.9904 - loss: 0.0347 - val_accuracy: 0.9427 - val_loss: 0.3599\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b065a5f53f0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Load the test image\n",
        "test_image = image.load_img('/content/drive/MyDrive/Data/Large-image-dataset/training/Legal/Legal_0_1068.jpeg', target_size = (64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = cnn.predict(test_image)\n",
        "print(result)\n",
        "\n",
        "if result[0][0] == 0:\n",
        "  prediction = 'Legal Ball'\n",
        "else:\n",
        "  prediction = 'No Ball'\n",
        "print(prediction)\n",
        "\n",
        "cnn.save('/content/drive/MyDrive/final_model.keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOHsO33z0MYJ",
        "outputId": "e27069d9-a41a-4cab-e00f-e57f9df1b020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
            "[[0.]]\n",
            "Legal Ball\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model testing using any image"
      ],
      "metadata": {
        "id": "zf1-MNqyxoHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.save('/content/drive/MyDrive/final_model.keras')\n",
        "\n",
        "# Load the model\n",
        "loaded_model = tf.keras.models.load_model('/content/drive/MyDrive/final_model.keras')\n",
        "\n",
        "# Load the test image\n",
        "test_image = image.load_img('/content/download.jpg', target_size = (64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "\n",
        "# Now you can use the loaded_model for predictions or further training\n",
        "result = loaded_model.predict(test_image)\n",
        "print(result)\n",
        "\n",
        "if result[0][0] == 0:\n",
        "  prediction = 'Legal Ball'\n",
        "else:\n",
        "  prediction = 'No Ball'\n",
        "print(prediction)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74d002b0-775f-427f-a71c-4da6188f879d",
        "id": "h7QKsPFnvOML"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
            "[[0.]]\n",
            "Legal Ball\n"
          ]
        }
      ]
    }
  ]
}